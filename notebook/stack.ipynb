{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac38838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error \n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import combinations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e3cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score01(train_t1, test_data_t1):\n",
    "    trn = train_t1.reshape(-1, 1)\n",
    "    trn = pd.DataFrame(trn, columns=['effect1'])\n",
    "    tst = pd.DataFrame({'effect1': test_data_t1}) \n",
    "    trn_tst = pd.concat([trn, tst], axis=0, ignore_index=True) \n",
    "    target = pd.read_csv('./dataset/data/target.csv')\n",
    "    target = target.reset_index(drop=True)\n",
    "    result = pd.concat([target, trn_tst], axis=1) \n",
    "    def calc_metric(result):\n",
    "        r = np.sqrt(np.sum((result.ce_1 - result.effect1)**2)/result.shape[0])/result.ce_1.mean() \n",
    "        return r \n",
    "    return calc_metric(result) \n",
    "\n",
    "def calc_score02(train_t1, test_data_t1):\n",
    "    trn = train_t1.reshape(-1, 1)\n",
    "    trn = pd.DataFrame(trn, columns=['effect1'])\n",
    "    tst = pd.DataFrame({'effect1': test_data_t1}) \n",
    "    trn_tst = pd.concat([trn, tst], axis=0, ignore_index=True) \n",
    "    target = pd.read_csv('./dataset/data/target.csv')\n",
    "    target = target.reset_index(drop=True)\n",
    "    result = pd.concat([target, trn_tst], axis=1) \n",
    "    def calc_metric(result):\n",
    "        r = np.sqrt(np.sum((result.ce_2 - result.effect1)**2)/result.shape[0])/result.ce_2.mean() \n",
    "        return r \n",
    "    return calc_metric(result) \n",
    "\n",
    "def bayesGridSearchCVParams(X, Y, objective='regression', scoring=None):\n",
    "    \"\"\"  \n",
    "    model: lgbm\n",
    "    X, Y dtype: int, float, category\n",
    "    objective:  'regression': 传统的均方误差回归。\n",
    "                'regression_l1': 使用L1损失的回归，也称为 Mean Absolute Error (MAE)。\n",
    "                'huber': 使用Huber损失的回归，这是均方误差和绝对误差的结合，特别适用于有异常值的情况。\n",
    "                'fair': 使用Fair损失的回归，这也是另一种对异常值鲁棒的损失函数。\n",
    "                'binary', \n",
    "                'multiclass'\n",
    "    scoring:\n",
    "    'neg_root_mean_squared_error', 'precision_micro', 'jaccard_micro', 'f1_macro', \n",
    "    'recall_weighted', 'neg_mean_absolute_percentage_error', 'f1_weighted', \n",
    "    'completeness_score', 'neg_brier_score', 'neg_mean_gamma_deviance', 'precision', \n",
    "    'adjusted_mutual_info_score', 'f1_samples', 'jaccard', 'neg_mean_poisson_deviance', \n",
    "    'precision_samples', 'recall', 'recall_samples', 'top_k_accuracy', 'roc_auc_ovr', \n",
    "    'mutual_info_score', 'jaccard_samples', 'positive_likelihood_ratio', 'f1_micro', \n",
    "    'adjusted_rand_score', 'accuracy', 'matthews_corrcoef', 'neg_mean_squared_log_error', \n",
    "    'precision_macro', 'rand_score', 'neg_log_loss', 'recall_macro', 'roc_auc_ovo', \n",
    "    'average_precision', 'jaccard_weighted', 'max_error', 'neg_median_absolute_error', \n",
    "    'jaccard_macro', 'roc_auc_ovo_weighted', 'fowlkes_mallows_score', 'precision_weighted', \n",
    "    'balanced_accuracy', 'v_measure_score', 'recall_micro', 'normalized_mutual_info_score', \n",
    "    'neg_mean_squared_error', 'roc_auc', 'roc_auc_ovr_weighted', 'f1', 'homogeneity_score', \n",
    "    'explained_variance', 'r2', 'neg_mean_absolute_error', 'neg_negative_likelihood_ratio'\n",
    "    \"\"\" \n",
    "    if Y[Y.columns[0]].dtype in (np.float32, np.float64, np.int32, np.int64):\n",
    "        y_type = 'regression' if objective is None else objective\n",
    "    elif Y[Y.columns[0]].unique().shape[0]==2:\n",
    "        y_type = 'binary'\n",
    "    elif Y[Y.columns[0]].unique().shape[0] > 2:\n",
    "        y_type = 'multiclass'\n",
    "    else:\n",
    "        raise ValueError('确认Y的类别数')\n",
    "#     print(y_type) \n",
    "    # grid \n",
    "    if y_type in ('multiclass', 'binary'): \n",
    "        params = {'boosting_type': 'gbdt', 'objective': y_type,\n",
    "                'class_weight': 'balanced', 'n_jobs': -1} \n",
    "        estimator = lgb.LGBMClassifier(**params) \n",
    "        param_grid = {'learning_rate': [0.01, 0.03, 0.05], \n",
    "                      'n_estimators': [500, 1000, 2000, 3000],\n",
    "                      'num_leaves': [7, 15, 31, 63],\n",
    "                      'min_child_samples': [1, 3, 5, 7 , 11], \n",
    "#                       'reg_alpha': [0, 0.01, 0.05, 0.1],\n",
    "                      'reg_lambda': [0, 0.01, 0.05, 0.1], \n",
    "                      'seed': [42]} \n",
    "    else:\n",
    "        params = {'boosting_type': 'gbdt',  'n_jobs': -1}\n",
    "        estimator = lgb.LGBMRegressor(**params) \n",
    "        param_grid = {\n",
    "                      'objective': ['regression'], # 'objective': ['regression', 'regression_l1', 'huber', 'fair'],\n",
    "                      'learning_rate': [0.03],  # 'learning_rate': [0.03], 0.01, 0.03, 0.05], \n",
    "                      'n_estimators': [200, 300, 400, 500, 800],  #'n_estimators': [300, 500, 1000, 2000, 3000], \n",
    "                      'num_leaves': [1, 3, 5, 7, 9],      # 'num_leaves': [7, 15, 31, 63, 127],\n",
    "                      'min_child_samples': [14, 18, 22, 25],  # 'min_child_samples': [1, 3, 5, 7, 10, 15, 20, 30],\n",
    "                      'reg_alpha': [0,  0.02, 0.05],\n",
    "                      'reg_lambda': [0,  0.02, 0.05], \n",
    "                      'seed': [42], \n",
    "                      'n_jobs': [-1]} \n",
    "    # search \n",
    "#     print(scoring) \n",
    "    grid = GridSearchCV(estimator, param_grid, \n",
    "#                          n_iter=300,\n",
    "                         cv=3, scoring = scoring, n_jobs=-1, verbose=0)\n",
    "    grid.fit(X, Y) \n",
    "    params.update(grid.best_params_)\n",
    "#     print('Best parameters found by grid search are:', params)\n",
    "#     print('best Score:', grid.best_score_)\n",
    "    return params \n",
    "\n",
    "def kfold_pred(X_train, X_test, y_train, y_test):\n",
    "    # 5-fold CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    oof_preds = np.zeros(X_train.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_tr, y_val = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "        tmp_params = bayesGridSearchCVParams(X_tr, y_tr, objective='regression', scoring='neg_root_mean_squared_error')\n",
    "        model = lgb.LGBMRegressor(**tmp_params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n",
    "                            early_stopping_rounds=50, verbose=False) \n",
    "        # Predict out-of-fold part of the training data\n",
    "        # as predict, 不能多次预测降低方差\n",
    "#         oof_preds[valid_index] = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "        # Average test predictions over the folds\n",
    "    # 多次预测取平均\n",
    "        test_preds += model.predict(X_test, num_iteration=model.best_iteration_) / kf.n_splits\n",
    "#     mse_oof = mean_squared_error(y_train, oof_preds)\n",
    "#     print(f\"Mean Squared Error for OOF predictions: {mse_oof:.4f}\")\n",
    "#     rmse_test = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    print(test_preds.shape)\n",
    "    return test_preds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938e821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3211c0c",
   "metadata": {},
   "source": [
    "## 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474747d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_T01 = pd.read_csv('./dataset/model/cfdml/cft01.csv')\n",
    "cf_T01 = cf_T01.values\n",
    "\n",
    "fdr_xt01 = pd.read_csv('./dataset/model/forestDRlearner/X_t01.csv')\n",
    "fdr_testt01 = pd.read_csv('./dataset/model/forestDRlearner/test_t01.csv')\n",
    "fdr_T01 = np.concatenate((fdr_xt01.values, fdr_testt01.values), axis=0) \n",
    "\n",
    "dr1_T01 = pd.read_csv('./dataset/model/drlearner/drt01.csv')\n",
    "dr1_T01 = dr1_T01.values\n",
    "\n",
    "dr2_T01 = pd.read_csv('./dataset/model/drlearner2/drt01.csv')\n",
    "dr2_T01 = dr2_T01.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e638d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t01 = pd.DataFrame({'cf_T01': cf_T01.reshape(-1), 'fdr_T01': fdr_T01.reshape(-1), \n",
    "                   'dr1_T01': dr1_T01.reshape(-1), 'dr2_T01': dr2_T01.reshape(-1)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41cccd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = t01.columns.to_list()\n",
    "t01['max_'] = np.max(t01[cols1], axis=1)\n",
    "t01['min_'] = np.min(t01[cols1], axis=1)\n",
    "t01['mean_'] = np.mean(t01[cols1], axis=1)\n",
    "t01['std_'] = np.std(t01[cols1], axis=1) \n",
    "t01['delta_'] = t01.max_ - t01.min_ \n",
    "iter1 = combinations(cols1, 2)\n",
    "for a, b in iter1:\n",
    "    t01['delta_%s'%a[:-4]+b[:-4]] = t01[a] - t01[b] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "597cbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = pd.read_csv('./dataset/data/target.csv')\n",
    "target1 = target1[['ce_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "290d0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10297,)\n",
      "nan Count (30891,)\n",
      "(10297,)\n",
      "nan Count (20594,)\n",
      "(10297,)\n",
      "nan Count (10297,)\n",
      "(10297,)\n",
      "nan Count (0,)\n"
     ]
    }
   ],
   "source": [
    "kf0 = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "result_pred1 = np.zeros(t01.shape[0])\n",
    "for tr_idx, tst_idx in kf0.split(t01):\n",
    "    X_train, X_test = t01.iloc[tr_idx], t01.iloc[tst_idx]\n",
    "    y_train, y_test = target1.iloc[tr_idx], target1.iloc[tst_idx]\n",
    "    pred_ = kfold_pred(X_train, X_test, y_train, y_test)\n",
    "    result_pred1[tst_idx] = pred_\n",
    "    print('nan Count', result_pred1[result_pred1==0].shape) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e9af71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1742048001728692"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score01(result_pred1[:-5000], result_pred1[-5000:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17278e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc15c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41652cc",
   "metadata": {},
   "source": [
    "##### t02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e3f54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_T02 = pd.read_csv('./dataset/model/cfdml/cft02.csv')\n",
    "cf_T02 = cf_T02.values\n",
    "\n",
    "fdr_xt02 = pd.read_csv('./dataset/model/forestDRlearner/X_t02.csv')\n",
    "fdr_testt02 = pd.read_csv('./dataset/model/forestDRlearner/test_t02.csv')\n",
    "fdr_T02 = np.concatenate((fdr_xt02.values, fdr_testt02.values), axis=0) \n",
    "\n",
    "dr1_T02 = pd.read_csv('./dataset/model/drlearner/drt02.csv')\n",
    "dr1_T02 = dr1_T02.values\n",
    "\n",
    "dr2_T02 = pd.read_csv('./dataset/model/drlearner2/drt02.csv')\n",
    "dr2_T02 = dr2_T02.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50ff6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "t02 = pd.DataFrame({'cf_T02': cf_T02.reshape(-1), 'fdr_T02': fdr_T02.reshape(-1), \n",
    "                   'dr1_T02': dr1_T02.reshape(-1), 'dr2_T02': dr2_T02.reshape(-1)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f16e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = t02.columns.to_list()\n",
    "t02['max_'] = np.max(t02[cols2], axis=1)\n",
    "t02['min_'] = np.min(t02[cols2], axis=1)\n",
    "t02['mean_'] = np.mean(t02[cols2], axis=1)\n",
    "t02['std_'] = np.std(t02[cols2], axis=1) \n",
    "t02['delta_'] = t02.max_ - t02.min_ \n",
    "iter2 = combinations(cols2, 2)\n",
    "for a, b in iter2:\n",
    "    t02['delta_%s'%a[:-4]+b[:-4]] = t02[a] - t02[b] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f366ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e12d3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = pd.read_csv('./dataset/data/target.csv')\n",
    "target2 = target2[['ce_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f61bcd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10297,)\n",
      "nan Count (30891,)\n",
      "(10297,)\n",
      "nan Count (20594,)\n",
      "(10297,)\n",
      "nan Count (10297,)\n",
      "(10297,)\n",
      "nan Count (0,)\n"
     ]
    }
   ],
   "source": [
    "kf2 = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "result_pred2 = np.zeros(t02.shape[0])\n",
    "for tr_idx, tst_idx in kf2.split(t02):\n",
    "    X_train, X_test = t02.iloc[tr_idx], t02.iloc[tst_idx]\n",
    "    y_train, y_test = target2.iloc[tr_idx], target2.iloc[tst_idx]\n",
    "    pred_ = kfold_pred(X_train, X_test, y_train, y_test)\n",
    "    result_pred2[tst_idx] = pred_\n",
    "    print('nan Count', result_pred2[result_pred2==0].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a19673bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03407833721780057"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score02(result_pred2[:-5000], result_pred2[-5000:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af56dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(pred01, pred02):\n",
    "    result = pd.DataFrame(np.concatenate((pred01.reshape(-1, 1), pred02.reshape(-1, 1)), axis=1), \n",
    "                    columns=['pred01', 'pred02'])\n",
    "    target = pd.read_csv('./dataset/data/target.csv')\n",
    "    result = pd.concat([target, result], axis=1)\n",
    "    def calc_metric(result):\n",
    "        r = np.sqrt(np.sum((result.ce_1 - result.pred01)**2)/result.shape[0])/result.ce_1.mean() + \\\n",
    "            np.sqrt(np.sum((result.ce_2 - result.pred02)**2)/result.shape[0])/result.ce_2.mean()\n",
    "        return r \n",
    "    return calc_metric(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffc90848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20828313739066978"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_score(result_pred1, result_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbd44d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.concatenate((result_pred1.reshape(-1, 1), result_pred2.reshape(-1, 1)), \n",
    "            axis=1), columns=['pred01', 'pred02']).to_csv('./dataset/stacked/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1fd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econml",
   "language": "python",
   "name": "econml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
